#!/usr/bin/env python3
"""
PostgreSQL Setup Validation Script for Medical RAG Pipeline

This script performs comprehensive validation of:
1. Database connectivity and pgvector functionality
2. Table structure and data integrity
3. Vector embedding functionality and performance
4. RAG pipeline operations
5. Application readiness

Usage:
Run this after complete setup to ensure everything is working correctly:
uv run scripts/validate_postgresql_setup.py
"""

import os
import sys
import asyncio
import time
from pathlib import Path
from typing import Dict, Any, List

# Add backend to path
sys.path.append(str(Path(__file__).parent.parent))

from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from dotenv import load_dotenv

from backend.lib.database import get_db
from backend.lib.embeddings import EmbeddingService
from backend.lib.rag_pipeline import RAGPipeline
from backend.lib.knowledge_graph import KnowledgeGraphService

# Load environment variables
load_dotenv()


class PostgreSQLValidator:
    """Comprehensive PostgreSQL setup validation"""
    
    def __init__(self):
        self.database_url = os.getenv("DATABASE_URL")
        
        if not self.database_url or not self.database_url.startswith("postgresql://"):
            raise ValueError(
                "DATABASE_URL must be PostgreSQL URL!\n"
                f"Current: {self.database_url}\n"
                "Expected: postgresql://user:password@localhost:5432/medical_rag_pg"
            )
        
        print(f"üìä Validating PostgreSQL setup: {self.database_url}")
        print("üîç Running comprehensive validation tests...")
    
    def test_database_connectivity(self):
        """Test basic database connectivity and pgvector functionality"""
        print("\nüîå Testing Database Connectivity")
        print("-" * 40)
        
        try:
            engine = create_engine(self.database_url)
            
            with engine.connect() as conn:
                # Basic connectivity
                result = conn.execute(text("SELECT version();"))
                version = result.fetchone()[0]
                print(f"   ‚úÖ PostgreSQL: {version[:50]}...")
                
                # pgvector extension
                result = conn.execute(text("""
                    SELECT extname, extversion 
                    FROM pg_extension 
                    WHERE extname = 'vector';
                """))
                vector_ext = result.fetchone()
                if vector_ext:
                    print(f"   ‚úÖ pgvector: version {vector_ext[1]}")
                else:
                    print("   ‚ùå pgvector extension not found!")
                    return False
                
                # Test vector operations
                result = conn.execute(text("SELECT '[1,2,3]'::vector(3) <-> '[1,1,1]'::vector(3) as distance;"))
                distance = result.fetchone()[0]
                print(f"   ‚úÖ Vector operations: distance test = {distance:.3f}")
                
                # Test vector similarity
                result = conn.execute(text("SELECT '[1,0,0]'::vector(3) <=> '[1,0,0]'::vector(3) as cosine_dist;"))
                cosine_dist = result.fetchone()[0]
                print(f"   ‚úÖ Cosine similarity: same vectors = {cosine_dist:.3f}")
                
                return True
                
            engine.dispose()
            
        except Exception as e:
            print(f"‚ùå Database connectivity test failed: {e}")
            return False
    
    def test_table_structure(self):
        """Test table structure and constraints"""
        print("\nüìã Testing Table Structure")
        print("-" * 40)
        
        try:
            engine = create_engine(self.database_url)
            
            with engine.connect() as conn:
                # Check all expected tables exist
                expected_tables = [
                    "drug_relations", "drug_metadata", "drug_product_stages",
                    "product_stage_descriptions", "food_interactions", "drug_dosage",
                    "vector_embeddings", "chat_sessions", "chat_messages"
                ]
                
                result = conn.execute(text("""
                    SELECT table_name 
                    FROM information_schema.tables 
                    WHERE table_schema = 'public'
                    ORDER BY table_name;
                """))
                actual_tables = [row[0] for row in result.fetchall()]
                
                missing_tables = [t for t in expected_tables if t not in actual_tables]
                if missing_tables:
                    print(f"   ‚ùå Missing tables: {missing_tables}")
                    return False
                
                print(f"   ‚úÖ All {len(expected_tables)} tables exist")
                
                # Check vector_embeddings table structure
                result = conn.execute(text("""
                    SELECT column_name, data_type, is_nullable
                    FROM information_schema.columns 
                    WHERE table_name = 'vector_embeddings'
                    ORDER BY ordinal_position;
                """))
                
                embedding_columns = {row[0]: (row[1], row[2]) for row in result.fetchall()}
                
                required_columns = ["id", "content", "embedding", "content_hash", "metadata", "source"]
                for col in required_columns:
                    if col in embedding_columns:
                        data_type, nullable = embedding_columns[col]
                        print(f"   ‚úÖ vector_embeddings.{col}: {data_type}")
                    else:
                        print(f"   ‚ùå vector_embeddings.{col}: MISSING")
                        return False
                
                # Check indexes
                result = conn.execute(text("""
                    SELECT indexname, tablename 
                    FROM pg_indexes 
                    WHERE tablename = 'vector_embeddings'
                    ORDER BY indexname;
                """))
                indexes = result.fetchall()
                print(f"   üìä vector_embeddings indexes: {len(indexes)}")
                for index_name, table_name in indexes:
                    print(f"     ‚Ä¢ {index_name}")
                
                return True
                
            engine.dispose()
            
        except Exception as e:
            print(f"‚ùå Table structure test failed: {e}")
            return False
    
    def test_data_integrity(self):
        """Test data integrity and counts"""
        print("\nüìä Testing Data Integrity")
        print("-" * 40)
        
        try:
            engine = create_engine(self.database_url)
            
            with engine.connect() as conn:
                tables_to_check = [
                    ("drug_relations", "Knowledge graph relations"),
                    ("drug_metadata", "Drug metadata"),
                    ("food_interactions", "Food interactions"),
                    ("drug_dosage", "Drug dosage info"),
                    ("drug_product_stages", "Product stages"),
                    ("product_stage_descriptions", "Stage descriptions"),
                    ("vector_embeddings", "Vector embeddings"),
                ]
                
                total_records = 0
                empty_critical_tables = []
                
                for table_name, description in tables_to_check:
                    result = conn.execute(text(f"SELECT COUNT(*) FROM {table_name};"))
                    count = result.fetchone()[0]
                    total_records += count
                    
                    status = "‚úÖ" if count > 0 else "‚ö†Ô∏è"
                    print(f"   {status} {description}: {count:,}")
                    
                    # Critical tables that should have data
                    if table_name in ["drug_relations", "vector_embeddings"] and count == 0:
                        empty_critical_tables.append(table_name)
                
                if empty_critical_tables:
                    print(f"\n‚ùå Critical tables are empty: {empty_critical_tables}")
                    print("Data ingestion or embedding generation may not be complete.")
                    return False
                
                print(f"\nüìä Total records: {total_records:,}")
                
                # Test some key relationships
                print("\nüîó Testing data relationships...")
                
                # Check drug relations structure
                result = conn.execute(text("""
                    SELECT 
                        COUNT(DISTINCT "xName") as unique_x,
                        COUNT(DISTINCT "yName") as unique_y,
                        COUNT(DISTINCT relation) as unique_relations
                    FROM drug_relations
                    LIMIT 1;
                """))
                rel_stats = result.fetchone()
                if rel_stats and rel_stats[0] > 0:
                    print(f"   ‚úÖ Knowledge graph: {rel_stats[0]:,} X entities, {rel_stats[1]:,} Y entities, {rel_stats[2]} relation types")
                
                # Check vector embeddings structure
                result = conn.execute(text("""
                    SELECT 
                        COUNT(DISTINCT source) as unique_sources,
                        AVG(token_count) as avg_tokens
                    FROM vector_embeddings
                    WHERE token_count IS NOT NULL;
                """))
                emb_stats = result.fetchone()
                if emb_stats and emb_stats[0]:
                    print(f"   ‚úÖ Embeddings: {emb_stats[0]} sources, avg {emb_stats[1]:.1f} tokens")
                
                return True
                
            engine.dispose()
            
        except Exception as e:
            print(f"‚ùå Data integrity test failed: {e}")
            return False
    
    async def test_embedding_functionality(self):
        """Test embedding service functionality"""
        print("\nü§ñ Testing Embedding Functionality")
        print("-" * 40)
        
        try:
            # Initialize embedding service
            embedding_service = EmbeddingService(
                provider="openai",
                model="text-embedding-3-small",
                dimensions=512
            )
            
            # Test single embedding creation
            print("   ‚Ä¢ Testing single embedding creation...")
            test_text = "Aspirin is used for pain relief and fever reduction."
            
            start_time = time.time()
            embedding = await embedding_service.create_embedding(test_text)
            creation_time = time.time() - start_time
            
            print(f"   ‚úÖ Single embedding: {len(embedding)} dims in {creation_time*1000:.1f}ms")
            
            if len(embedding) != 512:
                print(f"   ‚ùå Expected 512 dimensions, got {len(embedding)}")
                return False
            
            # Test database session
            db = next(get_db())
            
            try:
                # Test similarity search
                print("   ‚Ä¢ Testing similarity search...")
                
                start_time = time.time()
                similar_results = await embedding_service.search_similar(
                    db, 
                    "pain medication drug interaction",
                    limit=5,
                    min_similarity=0.3
                )
                search_time = time.time() - start_time
                
                print(f"   ‚úÖ Similarity search: {len(similar_results)} results in {search_time*1000:.1f}ms")
                
                # Show sample results
                if similar_results:
                    for i, result in enumerate(similar_results[:3]):
                        print(f"     {i+1}. {result['source']} (similarity: {result['similarity']:.3f})")
                        print(f"        {result['content'][:100]}...")
                else:
                    print("   ‚ö†Ô∏è  No similar results found (may need more data or lower threshold)")
                
                # Test embedding statistics
                stats = embedding_service.get_embedding_stats(db)
                print(f"   üìä Embedding stats: {stats['total_embeddings']:,} total, {stats['dimensions']} dims")
                
                return True
                
            finally:
                db.close()
            
        except Exception as e:
            print(f"‚ùå Embedding functionality test failed: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    async def test_rag_pipeline(self):
        """Test complete RAG pipeline functionality"""
        print("\nüß† Testing RAG Pipeline")
        print("-" * 40)
        
        try:
            db = next(get_db())
            
            try:
                # Initialize RAG pipeline
                rag_pipeline = RAGPipeline(db)
                
                # Test query analysis
                print("   ‚Ä¢ Testing query analysis...")
                test_query = "What are the side effects of aspirin when combined with warfarin?"
                
                analysis = await rag_pipeline.analyze_query(test_query)
                print(f"   ‚úÖ Query analysis: type={analysis.query_type}, confidence={analysis.confidence:.2f}")
                print(f"     Drugs: {analysis.extracted_drugs}")
                print(f"     Symptoms: {analysis.extracted_symptoms}")
                
                # Test enhanced retrieval
                print("   ‚Ä¢ Testing enhanced retrieval...")
                
                start_time = time.time()
                context = await rag_pipeline.enhanced_retrieve(
                    test_query,
                    options={
                        "maxVectorResults": 10,
                        "drugs": ["aspirin", "warfarin"]
                    }
                )
                retrieval_time = time.time() - start_time
                
                print(f"   ‚úÖ Enhanced retrieval: {retrieval_time*1000:.1f}ms")
                print(f"     Vector results: {len(context.vector_results)}")
                print(f"     Graph results: {len([v for v in context.graph_results.values() if v])}")
                
                # Test knowledge graph service
                print("   ‚Ä¢ Testing knowledge graph...")
                kg_service = KnowledgeGraphService(db)
                
                drug_info = kg_service.get_comprehensive_drug_info("aspirin", ["warfarin"])
                print(f"   ‚úÖ Knowledge graph: {len(drug_info.get('drugInfo', []))} drug records")
                
                # Test context formatting
                print("   ‚Ä¢ Testing context formatting...")
                formatted_context = rag_pipeline.format_context_for_llm(context)
                context_length = len(formatted_context)
                print(f"   ‚úÖ Context formatting: {context_length:,} characters")
                
                return True
                
            finally:
                db.close()
            
        except Exception as e:
            print(f"‚ùå RAG pipeline test failed: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def test_performance_benchmarks(self):
        """Test performance benchmarks"""
        print("\n‚ö° Testing Performance Benchmarks")
        print("-" * 40)
        
        try:
            engine = create_engine(self.database_url)
            
            with engine.connect() as conn:
                # Test vector similarity query performance
                print("   ‚Ä¢ Testing vector similarity performance...")
                
                # Get a sample embedding
                result = conn.execute(text("""
                    SELECT embedding 
                    FROM vector_embeddings 
                    LIMIT 1;
                """))
                sample_embedding = result.fetchone()
                
                if sample_embedding:
                    sample_vector = sample_embedding[0]
                    
                    # Test similarity search performance
                    similarity_queries = [
                        ("Cosine similarity top 10", f"SELECT content, embedding <=> '{sample_vector}'::vector as distance FROM vector_embeddings ORDER BY embedding <=> '{sample_vector}'::vector LIMIT 10;"),
                        ("Cosine similarity with filter", f"SELECT COUNT(*) FROM vector_embeddings WHERE embedding <=> '{sample_vector}'::vector < 0.5;"),
                    ]
                    
                    for query_name, query_sql in similarity_queries:
                        start_time = time.time()
                        result = conn.execute(text(query_sql))
                        result.fetchall()  # Fetch all results
                        query_time = time.time() - start_time
                        
                        print(f"   ‚úÖ {query_name}: {query_time*1000:.1f}ms")
                        
                        if query_time > 1.0:  # Slow query warning
                            print(f"     ‚ö†Ô∏è  Query slower than expected (>{query_time:.1f}s)")
                else:
                    print("   ‚ö†Ô∏è  No embeddings found for performance testing")
                
                # Test regular query performance
                print("   ‚Ä¢ Testing regular query performance...")
                
                regular_queries = [
                    ("Drug relations count", "SELECT COUNT(*) FROM drug_relations;"),
                    ("Join query", "SELECT dr.relation, dm.name FROM drug_relations dr JOIN drug_metadata dm ON dr.\"xName\" = dm.name LIMIT 100;"),
                    ("Food interactions lookup", "SELECT * FROM food_interactions WHERE \"drugName\" ILIKE '%aspirin%' LIMIT 10;"),
                ]
                
                for query_name, query_sql in regular_queries:
                    start_time = time.time()
                    result = conn.execute(text(query_sql))
                    result.fetchall()
                    query_time = time.time() - start_time
                    
                    print(f"   ‚úÖ {query_name}: {query_time*1000:.1f}ms")
                
                return True
                
            engine.dispose()
            
        except Exception as e:
            print(f"‚ùå Performance benchmark test failed: {e}")
            return False
    
    def generate_validation_report(self):
        """Generate a comprehensive validation report"""
        print("\nüìã Generating Validation Report")
        print("-" * 40)
        
        try:
            engine = create_engine(self.database_url)
            
            with engine.connect() as conn:
                # Database summary
                result = conn.execute(text("SELECT version();"))
                pg_version = result.fetchone()[0]
                
                result = conn.execute(text("SELECT extversion FROM pg_extension WHERE extname = 'vector';"))
                pgvector_version = result.fetchone()[0] if result.rowcount > 0 else "Not installed"
                
                # Data summary
                result = conn.execute(text("""
                    SELECT 
                        schemaname,
                        relname as tablename,
                        n_tup_ins as inserts,
                        n_tup_upd as updates,
                        n_tup_del as deletes
                    FROM pg_stat_user_tables
                    WHERE schemaname = 'public'
                    ORDER BY relname;
                """))
                table_stats = result.fetchall()
                
                # Index summary
                result = conn.execute(text("""
                    SELECT 
                        schemaname,
                        relname as tablename,
                        indexrelname as indexname,
                        idx_scan as scans
                    FROM pg_stat_user_indexes
                    WHERE schemaname = 'public'
                    ORDER BY relname, indexrelname;
                """))
                index_stats = result.fetchall()
                
                print("\n" + "=" * 60)
                print("üéâ PostgreSQL Medical RAG Pipeline Validation Report")
                print("=" * 60)
                
                print(f"\nüìä Database Configuration:")
                print(f"   ‚Ä¢ PostgreSQL Version: {pg_version[:50]}...")
                print(f"   ‚Ä¢ pgvector Version: {pgvector_version}")
                print(f"   ‚Ä¢ Database URL: {self.database_url}")
                
                print(f"\nüìã Table Statistics:")
                for schema, table, inserts, updates, deletes in table_stats:
                    print(f"   ‚Ä¢ {table}: {inserts:,} records, {updates:,} updates, {deletes:,} deletes")
                
                print(f"\nüîç Index Statistics:")
                current_table = None
                for schema, table, index, scans in index_stats:
                    if table != current_table:
                        print(f"   {table}:")
                        current_table = table
                    print(f"     ‚Ä¢ {index}: {scans:,} scans")
                
                # Vector embedding summary
                result = conn.execute(text("""
                    SELECT 
                        source,
                        COUNT(*) as count,
                        AVG(token_count) as avg_tokens
                    FROM vector_embeddings
                    WHERE token_count IS NOT NULL
                    GROUP BY source
                    ORDER BY count DESC;
                """))
                embedding_stats = result.fetchall()
                
                if embedding_stats:
                    print(f"\nü§ñ Embedding Statistics:")
                    total_embeddings = sum(row[1] for row in embedding_stats)
                    print(f"   ‚Ä¢ Total embeddings: {total_embeddings:,}")
                    for source, count, avg_tokens in embedding_stats:
                        print(f"     ‚Ä¢ {source}: {count:,} embeddings, avg {avg_tokens:.1f} tokens")
                
                print(f"\n‚úÖ Validation Status:")
                print(f"   ‚Ä¢ Database connectivity: PASSED")
                print(f"   ‚Ä¢ pgvector functionality: PASSED")
                print(f"   ‚Ä¢ Table structure: PASSED")
                print(f"   ‚Ä¢ Data integrity: PASSED")
                print(f"   ‚Ä¢ Embedding functionality: PASSED")
                print(f"   ‚Ä¢ RAG pipeline: PASSED")
                print(f"   ‚Ä¢ Performance benchmarks: PASSED")
                
                print(f"\nüöÄ PostgreSQL Medical RAG Pipeline Ready!")
                print(f"   ‚Ä¢ Update your .env to use PostgreSQL")
                print(f"   ‚Ä¢ Restart your application")
                print(f"   ‚Ä¢ Begin production operations")
                
                return True
                
            engine.dispose()
            
        except Exception as e:
            print(f"‚ùå Validation report generation failed: {e}")
            return False
    
    async def run_complete_validation(self):
        """Run all validation tests"""
        print("üöÄ Starting Complete PostgreSQL Validation")
        print("=" * 60)
        
        validation_tests = [
            ("Database Connectivity", self.test_database_connectivity),
            ("Table Structure", self.test_table_structure),
            ("Data Integrity", self.test_data_integrity),
            ("Embedding Functionality", self.test_embedding_functionality),
            ("RAG Pipeline", self.test_rag_pipeline),
            ("Performance Benchmarks", self.test_performance_benchmarks),
            ("Validation Report", self.generate_validation_report),
        ]
        
        passed_tests = 0
        total_tests = len(validation_tests)
        
        for test_name, test_func in validation_tests:
            print(f"\nüìã Running: {test_name}")
            print("-" * 50)
            
            try:
                if asyncio.iscoroutinefunction(test_func):
                    success = await test_func()
                else:
                    success = test_func()
                
                if success:
                    passed_tests += 1
                    print(f"‚úÖ {test_name}: PASSED")
                else:
                    print(f"‚ùå {test_name}: FAILED")
                    
            except Exception as e:
                print(f"‚ùå {test_name}: ERROR - {e}")
        
        print("\n" + "=" * 60)
        print(f"üéØ Validation Results: {passed_tests}/{total_tests} tests passed")
        
        if passed_tests == total_tests:
            print("üéâ All validation tests PASSED!")
            print("PostgreSQL Medical RAG Pipeline is ready for production!")
            return True
        else:
            failed_tests = total_tests - passed_tests
            print(f"‚ùå {failed_tests} test(s) FAILED!")
            print("Please review and fix issues before proceeding.")
            return False


def main():
    """Main function"""
    try:
        validator = PostgreSQLValidator()
        success = asyncio.run(validator.run_complete_validation())
        sys.exit(0 if success else 1)
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Validation interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()